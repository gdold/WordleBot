{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Original dictionary\n",
    "The Wordle dictionary, sorted alphabetically, is stored in wordle_dictionary.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from wordle_vocab import dictionary\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import json"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create Popularity Scores\n",
    "\n",
    "You need to first run `scrape_word_popularities.py` to obtain a csv file containing all of the popularity scores for every word in Wordle's vocabulary from Google Books. We then rework that into a nice dictionary of scores that can be used by Wordle bot.\n",
    "\n",
    "Current plan is to take the average popularity score of each word (case insensitive) from the past ten years. That will be a small offset we add to the entropy score of each word in entropy_guesser."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df=pd.read_csv(\"word_popularity_data.csv.zip\",compression=\"zip\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def score_averager(x,n_years=10):\n",
    "    return np.mean(x[-n_years:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"average_popularity\"]=df.apply(score_averager,axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>word</th>\n",
       "      <th>case</th>\n",
       "      <th>average_popularity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>aahed</td>\n",
       "      <td>Insensitive</td>\n",
       "      <td>4.629283e-08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>aalii</td>\n",
       "      <td>Insensitive</td>\n",
       "      <td>4.632601e-10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>aargh</td>\n",
       "      <td>Insensitive</td>\n",
       "      <td>4.016478e-08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>aarti</td>\n",
       "      <td>Insensitive</td>\n",
       "      <td>8.236386e-08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>abaca</td>\n",
       "      <td>Insensitive</td>\n",
       "      <td>4.356348e-08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>25738</td>\n",
       "      <td>zuzim</td>\n",
       "      <td>Insensitive</td>\n",
       "      <td>7.567169e-09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>25740</td>\n",
       "      <td>zygal</td>\n",
       "      <td>Insensitive</td>\n",
       "      <td>9.703162e-10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>25742</td>\n",
       "      <td>zygon</td>\n",
       "      <td>Insensitive</td>\n",
       "      <td>4.902521e-08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>25744</td>\n",
       "      <td>zymes</td>\n",
       "      <td>Insensitive</td>\n",
       "      <td>8.497195e-09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>25746</td>\n",
       "      <td>zymic</td>\n",
       "      <td>Insensitive</td>\n",
       "      <td>1.837635e-10</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>13038 rows Ã— 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        word         case  average_popularity\n",
       "0      aahed  Insensitive        4.629283e-08\n",
       "1      aalii  Insensitive        4.632601e-10\n",
       "3      aargh  Insensitive        4.016478e-08\n",
       "5      aarti  Insensitive        8.236386e-08\n",
       "7      abaca  Insensitive        4.356348e-08\n",
       "...      ...          ...                 ...\n",
       "25738  zuzim  Insensitive        7.567169e-09\n",
       "25740  zygal  Insensitive        9.703162e-10\n",
       "25742  zygon  Insensitive        4.902521e-08\n",
       "25744  zymes  Insensitive        8.497195e-09\n",
       "25746  zymic  Insensitive        1.837635e-10\n",
       "\n",
       "[13038 rows x 3 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "idx=df[\"case\"]==\"Insensitive\"\n",
    "columns=[\"word\",\"case\",\"average_popularity\"]\n",
    "df.loc[idx,columns]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0        aahed\n",
       "1        aalii\n",
       "3        aargh\n",
       "5        aarti\n",
       "7        abaca\n",
       "         ...  \n",
       "25738    zuzim\n",
       "25740    zygal\n",
       "25742    zygon\n",
       "25744    zymes\n",
       "25746    zymic\n",
       "Name: word, Length: 13038, dtype: object"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.loc[idx,\"word\"].str.lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "pop_dict=dict(zip(\n",
    "    df.loc[idx,\"word\"].str.lower().values,\n",
    "    df.loc[idx,\"average_popularity\"].values\n",
    ")\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Serialize data into file:\n",
    "json.dump( pop_dict, open( \"popularity_dict.json\", 'w' ) )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The contents of the above JSON file can just be copy and pasted into WordleBot/wordle_dictionary.py as `popularity_dict`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Scored dictionary"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First let's create a list of words from this data, sorted by word popularity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "pop_list = [x[0] for x in sorted(pop_dict.items(), key=lambda x: -x[1])] # List of dictionary words sorted from most to least popular"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here are the 100 most popular words from the dictionary: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['which', 'their', 'there', 'would', 'about', 'other', 'could', 'these', 'first', 'after', 'where', 'those', 'being', 'right', 'while', 'world', 'years', 'still', 'under', 'state', 'three', 'think', 'never', 'again', 'might', 'going', 'place', 'found', 'great', 'every', 'since', 'water', 'small', 'based', 'human', 'power', 'asked', 'often', 'order', 'women', 'house', 'using', 'point', 'given', 'until', 'group', 'table', 'large', 'later', 'study', 'press', 'level', 'early', 'shall', 'words', 'among', 'night', 'times', 'value', 'young', 'light', 'model', 'thing', 'white', 'woman', 'least', 'means', 'along', 'whole', 'black', 'heart', 'known', 'child', 'hands', 'above', 'sense', 'local', 'taken', 'death', 'voice', 'began', 'court', 'money', 'party', 'doing', 'front', 'close', 'terms', 'heard', 'short', 'class', 'space', 'field', 'third', 'blood', 'clear', 'quite', 'story', 'cases', 'major']\n"
     ]
    }
   ],
   "source": [
    "print(pop_list[:100])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And the 100 least popular: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['cowks', 'bwazi', 'weamb', 'jarps', 'atocs', 'cauks', 'byded', 'skaws', 'twals', 'yechs', 'kophs', 'cawks', 'chynd', 'sowff', 'inorb', 'syboe', 'buats', 'spyal', 'boygs', 'golps', 'tehrs', 'tozed', 'eilds', 'upjet', 'ikans', 'yitie', 'uraos', 'noups', 'souct', 'bedye', 'zhomo', 'gyeld', 'gawcy', 'ylkes', 'birsy', 'nemns', 'hawms', 'mozed', 'wudus', 'wauff', 'tozes', 'gymps', 'ylems', 'apoop', 'sdein', 'peeoy', 'zedas', 'pioys', 'fusks', 'hoaed', 'ryked', 'pyxed', 'zimbs', 'peghs', 'dsomo', 'atoks', 'advew', 'hohed', 'skyrs', 'wembs', 'avyze', 'awdls', 'azygy', 'byked', 'byrls', 'dsobo', 'dzhos', 'eevns', 'egmas', 'ennog', 'euked', 'evhoe', 'ewked', 'gowfs', 'hiois', 'humfs', 'hwyls', 'koaps', 'kuzus', 'nabks', 'odyls', 'omovs', 'phpht', 'poupt', 'pyins', 'qapik', 'qophs', 'sdayn', 'skyfs', 'snebs', 'sowfs', 'syped', 'tiyns', 'viffs', 'voema', 'vutty', 'xysts', 'yesks', 'yrivd', 'zexes']\n"
     ]
    }
   ],
   "source": [
    "print(pop_list[-100:])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Come on, there's no way some of these are words! Still, Wordle allows them so we'll include them, I guess..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create letter scores\n",
    "The score for each letter is the total number of times it occurs in the dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "pop_list_reverse = pop_list[::-1] # so that final dictionary will be sorted alphabetically within equal scores\n",
    "\n",
    "str_dictionary = ''.join(pop_list_reverse)\n",
    "alphabet = 'abcdefghijklmnopqrstuvwxyz'\n",
    "alphabet_list = [a for a in alphabet]\n",
    "letter_scores_list = [str_dictionary.count(letter) for letter in alphabet]\n",
    "\n",
    "# Score of each letter is just the number of times it appears in the dictionary\n",
    "letter_scores = dict(zip(alphabet_list,letter_scores_list))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Here are the letter scores this generates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "letter_scores = {'a': 5990, 'b': 1627, 'c': 2028, 'd': 2453, 'e': 6662, 'f': 1115, 'g': 1644, 'h': 1760, 'i': 3759, 'j': 291, 'k': 1505, 'l': 3371, 'm': 1976, 'n': 2952, 'o': 4438, 'p': 2019, 'q': 112, 'r': 4158, 's': 6665, 't': 3295, 'u': 2511, 'v': 694, 'w': 1039, 'x': 288, 'y': 2074, 'z': 434}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create dictionary scores\n",
    "For each word in the dictionary, the score is the sum of its *unique* letter scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Score of a word is the sum of the *unique* letter scores in each word\n",
    "dictionary_scores_list = [sum([letter_scores[letter] for letter in set(word)]) for word in pop_list_reverse]\n",
    "dictionary_scores = dict(zip(pop_list_reverse,dictionary_scores_list))\n",
    "scored_dictionary = sorted(dictionary_scores, key=dictionary_scores.get)\n",
    "scored_dictionary.reverse() # Sort by score *descending*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here are the 100 highest-scoring words:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['arose', 'aeros', 'soare', 'raise', 'arise', 'serai', 'aesir', 'reais', 'aloes', 'stoae', 'toeas', 'laser', 'earls', 'arles', 'reals', 'rales', 'lares', 'lears', 'seral', 'laers', 'rates', 'tears', 'stare', 'aster', 'taser', 'tares', 'teras', 'stear', 'resat', 'reast', 'arets', 'strae', 'earst', 'aeons', 'aisle', 'snare', 'earns', 'nears', 'nares', 'saner', 'reans', 'anise', 'saine', 'isnae', 'ureas', 'aures', 'ursae', 'urase', 'least', 'tales', 'steal', 'slate', 'stale', 'tesla', 'stela', 'taels', 'setal', 'teals', 'salet', 'leats', 'reads', 'dares', 'dears', 'arsed', 'rased', 'sared', 'eards', 'paseo', 'psoae', 'osier', 'lanes', 'leans', 'slane', 'neals', 'elans', 'antes', 'stane', 'nates', 'neats', 'stean', 'etnas', 'years', 'ayres', 'sayer', 'arsey', 'eyras', 'resay', 'ideas', 'aside', 'aides', 'acres', 'races', 'cares', 'scare', 'carse', 'serac', 'acers', 'escar', 'scrae', 'spare']\n"
     ]
    }
   ],
   "source": [
    "print(scored_dictionary[:100])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The entire `scored_dictionary` is included in ```WordleBot/wordle_dictionary.py```"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
